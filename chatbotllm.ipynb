{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0475a745-cdb1-4ffd-b1b6-4fb4f33a182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM, TFBertForSequenceClassification, TFGPT2LMHeadModel, AutoTokenizer, pipeline\n",
    "import tensorflow as tf\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "import speech_recognition as sr\n",
    "from cachetools import TTLCache\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be256db5-8248-4dd1-80ec-024f6ab2002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cpu\n",
      "Transformers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "from transformers import pipeline\n",
    "print(\"Transformers loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f999b17-e992-417b-a8cd-3fa7ec493ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = TTLCache(maxsize=100, ttl=300)  # Cache 100 responses, expire after 5 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32268393-213d-4c62-acdc-ebee83274a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self):\n",
    "        self.translation_tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "        self.nlu_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.response_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "        self.translation_model = None\n",
    "        self.nlu_model = None\n",
    "        self.response_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5125a524-929c-4e79-b669-58c01275493f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def load_translation_model(self):\n",
    "        if self.translation_model is None:\n",
    "            self.translation_model = TFAutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "        return self.translation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "320500ce-8dda-4bf2-8b86-5f89e75bce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nlu_model(self):\n",
    "        if self.nlu_model is None:\n",
    "            self.nlu_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "        return self.nlu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c8fa1a-f4a7-41f0-9c36-09fe87854505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_response_model(self):\n",
    "        if self.response_model is None:\n",
    "            self.response_model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "        return self.response_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1532c3e9-d477-4a32-83c6-383a6b3d9289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response: ¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "from googletrans import Translator\n",
    "\n",
    "# Initialize the Google Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Load pre-trained model for text generation\n",
    "text_generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Function to generate chatbot response\n",
    "def get_response(user_input):\n",
    "    response = text_generator(user_input, max_length=50, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# Function for translation using Google Translate\n",
    "def translate(text, src_lang=\"auto\", tgt_lang=\"es\"):\n",
    "    translation = translator.translate(text, src=src_lang, dest=tgt_lang)\n",
    "    return translation.text\n",
    "\n",
    "# Multilingual Chatbot Function\n",
    "def multilingual_chatbot(user_input, user_language=\"en\"):\n",
    "    # Translate user input to English (if it's not in English)\n",
    "    if user_language != \"en\":\n",
    "        translated_input = translate(user_input, src_lang=user_language, tgt_lang=\"en\")\n",
    "    else:\n",
    "        translated_input = user_input\n",
    "    \n",
    "    # Get the chatbot response in English\n",
    "    response = get_response(translated_input)\n",
    "    \n",
    "    # Translate the response back to the user's preferred language\n",
    "    if user_language != \"en\":\n",
    "        translated_response = translate(response, src_lang=\"en\", tgt_lang=user_language)\n",
    "    else:\n",
    "        translated_response = response\n",
    "    \n",
    "    return translated_response\n",
    "\n",
    "# Example usage\n",
    "user_input = \"¿Cómo estás?\"\n",
    "user_language = \"en\"  # Spanish\n",
    "\n",
    "# Get chatbot response in the user's language\n",
    "response = multilingual_chatbot(user_input, user_language)\n",
    "print(f\"Chatbot response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f62c8f3a-de4b-4847-98aa-6b673982ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent_entities(self, text):\n",
    "        model = self.load_nlu_model()\n",
    "        inputs = self.nlu_tokenizer(text, return_tensors=\"tf\", padding=True)\n",
    "        outputs = model(inputs['input_ids'])\n",
    "        intent = tf.argmax(outputs.logits, axis=1).numpy()[0]\n",
    "        entities = []  # Placeholder, entity recognition would require a more complex model or pipeline\n",
    "        return intent, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b4c581f-fba4-4029-a68e-3e55ebc5360f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def generate_response(self, intent, entities, context):\n",
    "        model = self.load_response_model()\n",
    "        prompt = f\"Intent: {intent}, Entities: {entities}, Context: {context}\\nResponse:\"\n",
    "        inputs = self.response_tokenizer(prompt, return_tensors=\"tf\", padding=True)\n",
    "        outputs = model.generate(inputs['input_ids'])\n",
    "        return self.response_tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7cc7921-63e7-47f5-8805-d2097b44b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def chatbot_pipeline(self, user_input, user_language):\n",
    "        cache_key = f\"{user_input}-{user_language}\"\n",
    "        if cache_key in cache:\n",
    "            return cache[cache_key]\n",
    "        \n",
    "        translated_input = self.translate(user_input, user_language)\n",
    "        intent, entities = self.predict_intent_entities(translated_input)\n",
    "        response = self.generate_response(intent, entities, context={})\n",
    "        final_response = self.translate(response, 'en', user_language)\n",
    "        cache[cache_key] = final_response\n",
    "        return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "430f2678-786c-4bab-bf38-7ee0f6f63f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"quit\":\n",
    "            print(\"Bot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        intent_tag = predict_intent(user_input)\n",
    "        \n",
    "        if intent_tag == \"show_info\":\n",
    "            show_info = get_show_info(user_input)\n",
    "            if show_info:\n",
    "                response = f\"{show_info['show']} is available at {show_info['time']}. Costs: {', '.join([f'{c['type']}: {c['cost']}' for c in show_info['costs']])}\"\n",
    "            else:\n",
    "                response = \"Sorry, I couldn't find that show.\"\n",
    "        else:\n",
    "            response = get_response(intent_tag)\n",
    "        \n",
    "        print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e50a4f-7860-4c59-a653-ab5559d91a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  helllo\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'translator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m message\n\u001b[1;32m----> 4\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241m.\u001b[39mtranslate(text, src\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, dest\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translator' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    text = message\n",
    "    translated = translator.translate(text, src='en', dest='es')\n",
    "    if message.lower() == \"quit\":\n",
    "        break\n",
    "    response = chatbot_response(message)\n",
    "    print(f\"Bot: {response}\")\n",
    "    print(f\"Translated Text: {translated.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95e17789-f3af-4873-963b-64a4b8663e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/speech-to-text', methods=['POST'])\n",
    "def speech_to_text():\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_file = request.files['file']\n",
    "\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            return jsonify({\"text\": text})\n",
    "        except sr.UnknownValueError:\n",
    "            return jsonify({\"error\": \"Speech not recognized\"}), 400\n",
    "        except sr.RequestError:\n",
    "            return jsonify({\"error\": \"Speech recognition service error\"}), 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e4967a-7eac-4c3a-a92f-cd0bc825dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Initialize chatbot\n",
    "chatbot = Chatbot()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/chatbot', methods=['POST'])\n",
    "def chatbot_response():\n",
    "    user_input = request.json.get('text')\n",
    "    user_language = request.json.get('language', 'en')\n",
    "    response = chatbot.chatbot_pipeline(user_input, user_language)\n",
    "    return jsonify({\"response\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec33ce78-6983-4c73-a5da-8a3659520985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a9aaa53-ecae-4d6c-8392-a6eb23ba7336",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flask\\app.py:625\u001b[0m, in \u001b[0;36mFlask.run\u001b[1;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwerkzeug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_simple\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m     \u001b[43mrun_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;66;03m# reset the first request information if the development server\u001b[39;00m\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# reset normally.  This makes it possible to restart the server\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# without reloader and that stuff from an interactive shell.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_first_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\werkzeug\\serving.py:1106\u001b[0m, in \u001b[0;36mrun_simple\u001b[1;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_reloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_with_reloader\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1106\u001b[0m     \u001b[43mrun_with_reloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve_forever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreloader_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreloader_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreloader_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     srv\u001b[38;5;241m.\u001b[39mserver_close()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\werkzeug\\_reloader.py:458\u001b[0m, in \u001b[0;36mrun_with_reloader\u001b[1;34m(main_func, extra_files, exclude_patterns, interval, reloader_type)\u001b[0m\n\u001b[0;32m    456\u001b[0m             reloader\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m         \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestart_with_reloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "%tb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb6c81-0f74-4da6-8366-aba52d148fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
