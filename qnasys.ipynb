{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f165a480-673e-48fa-bccc-af38a6190f56",
   "metadata": {},
   "source": [
    "The goal of this project is to develop a system that can classify legal documents (such as court rulings, briefs, and statutes) based on their content and predict outcomes of legal cases. This project tackles a real-world problem by assisting law firms and legal professionals in analyzing large volumes of legal documents, predicting case outcomes, and making data-driven decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "859be1fe-ec99-457e-aada-2c6d9d40aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     ID                     name  \\\n",
      "0           0  50606              Roe v. Wade   \n",
      "1           1  50613      Stanley v. Illinois   \n",
      "2           2  50623  Giglio v. United States   \n",
      "3           3  50632             Reed v. Reed   \n",
      "4           4  50643     Miller v. California   \n",
      "\n",
      "                                      href   docket  term  \\\n",
      "0    https://api.oyez.org/cases/1971/70-18    70-18  1971   \n",
      "1  https://api.oyez.org/cases/1971/70-5014  70-5014  1971   \n",
      "2    https://api.oyez.org/cases/1971/70-29    70-29  1971   \n",
      "3     https://api.oyez.org/cases/1971/70-4     70-4  1971   \n",
      "4    https://api.oyez.org/cases/1971/70-73    70-73  1971   \n",
      "\n",
      "           first_party   second_party  \\\n",
      "0             Jane Roe     Henry Wade   \n",
      "1  Peter Stanley, Sr.        Illinois   \n",
      "2         John Giglio   United States   \n",
      "3           Sally Reed     Cecil Reed   \n",
      "4        Marvin Miller     California   \n",
      "\n",
      "                                               facts  facts_len  \\\n",
      "0  <p>In 1970, Jane Roe (a fictional name used in...        501   \n",
      "1  <p>Joan Stanley had three children with Peter ...        757   \n",
      "2  <p>John Giglio was convicted of passing forged...        495   \n",
      "3  <p>The Idaho Probate Code specified that \"male...        378   \n",
      "4  <p>Miller, after conducting a mass mailing cam...        305   \n",
      "\n",
      "   majority_vote  minority_vote first_party_winner     decision_type  \\\n",
      "0              7              2               True  majority opinion   \n",
      "1              5              2               True  majority opinion   \n",
      "2              7              0               True  majority opinion   \n",
      "3              7              0               True  majority opinion   \n",
      "4              5              4               True  majority opinion   \n",
      "\n",
      "         disposition       issue_area  \n",
      "0           reversed              NaN  \n",
      "1  reversed/remanded     Civil Rights  \n",
      "2  reversed/remanded      Due Process  \n",
      "3  reversed/remanded     Civil Rights  \n",
      "4   vacated/remanded  First Amendment  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[281], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Assuming the text data is in a column called 'text'\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\ayush\\Downloads\\justice.csv\\justice.csv')  # Replace with your dataset path\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Assuming the text data is in a column called 'text'\n",
    "texts = df['text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0a8be-10d5-4216-bf73-f0779cdc880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b838ae84c448efa6ae632ed9828515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ayush\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7d5825639a478f8c0c8ec66e4f8cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "822e7eb7-e783-4cda-82ed-dda409efcc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_words ['see', 'outisde', 'court', 'get', 'hell']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class LegalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset objects\n",
    "train_dataset = LegalDataset(train_encodings, train_labels.tolist())\n",
    "test_dataset = LegalDataset(test_encodings, test_labels.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "59982946-4c94-497d-835a-be33659306e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load a pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(set(train_labels)))\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "432a37ed-d00b-4dcc-aabc-9a074fc71a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['see', 'outisd', 'court', 'get', 'hell']\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"Evaluation results: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d8a4ffeb-5f03-4529-8f9e-808b083d2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['see', 'outisde', 'court', 'get', 'hell']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d313c562-6883-4d79-be3c-135dafae8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8cbd3e3d-9cec-4195-877e-db0fb4601ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos tagged words [('Will', 'MD'), ('see', 'VB'), ('You', 'PRP'), ('outisde', 'VB'), ('court', 'NN'), ('get', 'NN'), ('to', 'TO'), ('hell', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "pos_tags=nltk.pos_tag(words)\n",
    "print(\"pos tagged words\" , pos_tags)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a70f224-17c5-48ad-b30a-837ede2ab74e",
   "metadata": {},
   "source": [
    "3.Feature extarction \n",
    "td-idf vector to convert word to vector which is goood for medium sized data sets. it coverts words to vector form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5460dd04-218a-4b85-a7ae-c652b77b52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7550edb0-170e-4cf9-a8f6-77f9be7b7518",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"The court ruled in favor of the defendant.\",\n",
    "    \"The defendant was found guilty of the crime.\",\n",
    "    \"The judge dismissed the case due to lack of evidence.\",\n",
    "    \"The jury awarded damages to the plaintiff.\",\n",
    "    \"The case was settled out of court.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "90757dc0-87d9-42f6-ab41-9c2450c84e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "tfidf_matrix=tfidf.fit_transform(corpus)\n",
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray() , columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f4e4b9ee-865e-4c84-826f-3b800996f63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    awarded      case     court     crime   damages  defendant  dismissed  \\\n",
      "0  0.000000  0.000000  0.343162  0.000000  0.000000   0.343162   0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.425341  0.000000   0.343162   0.000000   \n",
      "2  0.000000  0.294062  0.000000  0.000000  0.000000   0.000000   0.364482   \n",
      "3  0.424127  0.000000  0.000000  0.000000  0.424127   0.000000   0.000000   \n",
      "4  0.000000  0.380444  0.380444  0.000000  0.000000   0.000000   0.000000   \n",
      "\n",
      "        due  evidence     favor  ...      jury      lack        of       out  \\\n",
      "0  0.000000  0.000000  0.425341  ...  0.000000  0.000000  0.239630  0.000000   \n",
      "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.239630  0.000000   \n",
      "2  0.364482  0.364482  0.000000  ...  0.000000  0.364482  0.205343  0.000000   \n",
      "3  0.000000  0.000000  0.000000  ...  0.424127  0.000000  0.000000  0.000000   \n",
      "4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.265664  0.471551   \n",
      "\n",
      "   plaintiff     ruled   settled       the        to       was  \n",
      "0   0.000000  0.425341  0.000000  0.405354  0.000000  0.000000  \n",
      "1   0.000000  0.000000  0.000000  0.405354  0.000000  0.343162  \n",
      "2   0.000000  0.000000  0.000000  0.347355  0.294062  0.000000  \n",
      "3   0.424127  0.000000  0.000000  0.404198  0.342183  0.000000  \n",
      "4   0.000000  0.000000  0.471551  0.224697  0.000000  0.380444  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f5c347a2-4aaf-4ae0-a680-77c09ac06a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d994ffae-20f3-459f-9543-8c697426025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       civil       0.00      1.00      0.00       0.0\n",
      "    criminal       1.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.50      0.50      0.00       1.0\n",
      "weighted avg       1.00      0.00      0.00       1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the SVM classifier with a linear kernel\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred , zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b8906f56-fdd2-4734-80f2-3d686cff9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "802161f6-3173-48af-8fca-5ae21c9c764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['criminal', 'criminal' , 'civil' , 'civil' , 'civil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "24a8a7ce-e9cc-4036-9b19-684edf786d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in X: 5\n",
      "Number of samples in y: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in X:\", tfidf_df.shape[0])\n",
    "print(\"Number of samples in y:\", len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f5ed1d6f-8490-444a-8d6e-ebdc5845ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "38745c6c-ac35-4ff5-a3fe-0ccf150103eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4, 24)\n",
      "y_train shape: 4\n",
      "X_test shape: (1, 24)\n",
      "y_test shape: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", len(y_train))\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "42bc6e1c-c2dd-46d8-8d5c-2b57675f39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a885a4eb-3291-420c-a6f5-971053e8c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_l1=LogisticRegression(penalty='l1' , solver='liblinear', random_state=42)\n",
    "lr_l1.fit(X_train,y_train)\n",
    "y_pred_l1=lr_l1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7a7ef4f8-f26c-4fdb-8df6-2e40ee4b35a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Regularization - Accuracy: 0.0\n",
      "L1 Regularization - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       civil       0.00      1.00      0.00       0.0\n",
      "    criminal       1.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.50      0.50      0.00       1.0\n",
      "weighted avg       1.00      0.00      0.00       1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"L1 Regularization - Accuracy:\", accuracy_score(y_test, y_pred_l1))\n",
    "print(\"L1 Regularization - Classification Report:\\n\", classification_report(y_test, y_pred_l1 ,zero_division=1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b7f83ab9-1c21-47eb-ac46-3f3d154eaedd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'civil'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Count the occurrences of each class in the training data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Distribution in y_train:\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_counts)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'civil'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count the occurrences of each class in the training data\n",
    "class_counts = np.bincount(y_train)\n",
    "print(\"Class Distribution in y_train:\", class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8c1d503c-9fb3-4a98-b291-a0f6e7d99f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       civil       0.00      1.00      0.00       0.0\n",
      "    criminal       1.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.50      0.50      0.00       1.0\n",
      "weighted avg       1.00      0.00      0.00       1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Initialize the GBM classifier with class weights\n",
    "gbm_classifier = GradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=150,  # Increase the number of trees\n",
    "    learning_rate=0.05,  # Reduce learning rate\n",
    "    max_depth=5,  # Slightly deeper trees to allow more complex learning\n",
    "    subsample=0.8  # Use only 80% of data for each tree to add randomness\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "gbm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6465959-2713-4c55-a99e-d48313871cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
