{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6518c4ef-7a83-45e4-8c70-f38d6bff39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
      "0  570306133677760513           neutral                        1.0000   \n",
      "1  570301130888122368          positive                        0.3486   \n",
      "2  570301083672813571           neutral                        0.6837   \n",
      "3  570301031407624196          negative                        1.0000   \n",
      "4  570300817074462722          negative                        1.0000   \n",
      "\n",
      "  negativereason  negativereason_confidence         airline  \\\n",
      "0            NaN                        NaN  Virgin America   \n",
      "1            NaN                     0.0000  Virgin America   \n",
      "2            NaN                        NaN  Virgin America   \n",
      "3     Bad Flight                     0.7033  Virgin America   \n",
      "4     Can't Tell                     1.0000  Virgin America   \n",
      "\n",
      "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
      "0                    NaN     cairdin                 NaN              0   \n",
      "1                    NaN    jnardino                 NaN              0   \n",
      "2                    NaN  yvonnalynn                 NaN              0   \n",
      "3                    NaN    jnardino                 NaN              0   \n",
      "4                    NaN    jnardino                 NaN              0   \n",
      "\n",
      "                                                text tweet_coord  \\\n",
      "0                @VirginAmerica What @dhepburn said.         NaN   \n",
      "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
      "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
      "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
      "\n",
      "               tweet_created tweet_location               user_timezone  \n",
      "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
      "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
      "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
      "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
      "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset (assuming it's in CSV format)\n",
    "df = pd.read_csv(r'C:\\Users\\ayush\\Downloads\\Tweets.csv\\Tweets.csv')\n",
    "\n",
    "# Inspect the data\n",
    "print(data.head())\n",
    "\n",
    "# Extract the features and labels\n",
    "X = data[['text', 'tweet_id']]  # Assuming numerical features are included\n",
    "y = data['airline_sentiment']  # Assuming the labels are in a column named 'sentiment'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5abe34e2-c957-41aa-9a1b-25f2d2893358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_22356\\635708292.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['text'] = X['text'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = text.split()  # Tokenize\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stop_words]  # Lemmatize and remove stop words\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "X['text'] = X['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e09b096e-1280-4268-a4ec-56397552a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use CountVectorizer instead of TfidfVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=5000)  # Adjust the max_features as needed\n",
    "X_count = count_vectorizer.fit_transform(X['text'])\n",
    "\n",
    "# Combine the CountVectorizer features with the numerical features\n",
    "X_combined = hstack([X_count, X[['tweet_id']].values])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fefef62d-a730-48a5-9132-21b7cf08bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the base models\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_clf=rf.fit(X_train, y_train)  # Fitting the model\n",
    "\n",
    "# Now access the feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "nb = MultinomialNB()\n",
    "nb_clf=nb.fit(X_train,y_train)\n",
    "\n",
    "# Define the stacking classifier\n",
    "estimators = [\n",
    "    ('rf', rf),\n",
    "    ('nb', nb)\n",
    "]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "67e0f6ad-88ec-48e8-a439-1c44b3cb381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the function to optimize\n",
    "def optimize_rf(n_estimators, max_depth, min_samples_split):\n",
    "    rf.n_estimators = int(n_estimators)\n",
    "    rf.max_depth = int(max_depth)\n",
    "    rf.min_samples_split = int(min_samples_split)\n",
    "    \n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    y_pred = stacking_clf.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Define the hyperparameter space\n",
    "pbounds = {\n",
    "    'n_estimators': (50, 200),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=optimize_rf,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f340863d-bbe7-497d-b5b4-28dcdb89edf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7886   \u001b[39m | \u001b[39m5.622    \u001b[39m | \u001b[39m9.606    \u001b[39m | \u001b[39m159.8    \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.7896   \u001b[39m | \u001b[35m7.191    \u001b[39m | \u001b[35m3.248    \u001b[39m | \u001b[35m73.4     \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.7865   \u001b[39m | \u001b[39m3.407    \u001b[39m | \u001b[39m8.929    \u001b[39m | \u001b[39m140.2    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7893   \u001b[39m | \u001b[39m7.957    \u001b[39m | \u001b[39m2.165    \u001b[39m | \u001b[39m195.5    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.7886   \u001b[39m | \u001b[39m8.827    \u001b[39m | \u001b[39m3.699    \u001b[39m | \u001b[39m77.27    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.7896   \u001b[39m | \u001b[39m5.879    \u001b[39m | \u001b[39m3.947    \u001b[39m | \u001b[39m69.38    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7879   \u001b[39m | \u001b[39m4.398    \u001b[39m | \u001b[39m9.821    \u001b[39m | \u001b[39m187.9    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.7886   \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m72.57    \u001b[39m |\n",
      "| \u001b[35m9        \u001b[39m | \u001b[35m0.79     \u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m68.63    \u001b[39m |\n",
      "| \u001b[35m10       \u001b[39m | \u001b[35m0.7903   \u001b[39m | \u001b[35m8.643    \u001b[39m | \u001b[35m2.12     \u001b[39m | \u001b[35m58.06    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7893   \u001b[39m | \u001b[39m9.888    \u001b[39m | \u001b[39m7.901    \u001b[39m | \u001b[39m51.47    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7883   \u001b[39m | \u001b[39m3.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m54.68    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7893   \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m5.653    \u001b[39m | \u001b[39m61.82    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7889   \u001b[39m | \u001b[39m6.246    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m62.44    \u001b[39m |\n",
      "| \u001b[35m15       \u001b[39m | \u001b[35m0.791    \u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m2.0      \u001b[39m | \u001b[35m54.89    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7906   \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m50.0     \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7906   \u001b[39m | \u001b[39m9.92     \u001b[39m | \u001b[39m2.549    \u001b[39m | \u001b[39m108.3    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7896   \u001b[39m | \u001b[39m8.468    \u001b[39m | \u001b[39m9.837    \u001b[39m | \u001b[39m106.9    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.7896   \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m115.6    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7896   \u001b[39m | \u001b[39m8.643    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m101.5    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7883   \u001b[39m | \u001b[39m3.016    \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m109.1    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7896   \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m6.481    \u001b[39m | \u001b[39m111.5    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7883   \u001b[39m | \u001b[39m9.978    \u001b[39m | \u001b[39m9.768    \u001b[39m | \u001b[39m95.44    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7889   \u001b[39m | \u001b[39m9.825    \u001b[39m | \u001b[39m2.113    \u001b[39m | \u001b[39m171.2    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.7906   \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m123.3    \u001b[39m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer.maximize(init_points=5, n_iter=20)\n",
    "\n",
    "# Extract the best parameters\n",
    "best_params = optimizer.max['params']\n",
    "rf.n_estimators = int(best_params['n_estimators'])\n",
    "rf.max_depth = int(best_params['max_depth'])\n",
    "rf.min_samples_split = int(best_params['min_samples_split'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b5dc8482-d86c-4c1a-a087-abcbdd9cca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred =stacking_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9119dabb-6622-4933-8d02-c77009abb5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Stacking Classifier Accuracy: 0.7910\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.93      0.87      1889\n",
      "     neutral       0.65      0.42      0.51       580\n",
      "    positive       0.77      0.67      0.72       459\n",
      "\n",
      "    accuracy                           0.79      2928\n",
      "   macro avg       0.75      0.68      0.70      2928\n",
      "weighted avg       0.78      0.79      0.78      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Stacking Classifier Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "32bb7e40-588d-4ca6-a62a-782a362c453d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5000 is out of bounds for axis 0 with size 5000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mbarh(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(indices)), feature_importances[indices], align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(indices)), [\u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature Importance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop 10 Important Features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5000 is out of bounds for axis 0 with size 5000"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "feature_importances = rf.feature_importances_ \n",
    "indices = np.argsort(feature_importances)[-10:]  # Top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(indices)), feature_importances[indices], align='center')\n",
    "plt.yticks(range(len(indices)), [tfidf.get_feature_names_out()[i] for i in indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Important Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373ece3-acc3-4d71-97c2-76a9fd9ebf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
